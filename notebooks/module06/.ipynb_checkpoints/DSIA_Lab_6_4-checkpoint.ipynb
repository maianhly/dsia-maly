{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Load-Data\" data-toc-modified-id=\"1.-Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>1. Load Data</a></span></li><li><span><a href=\"#2.-EDA\" data-toc-modified-id=\"2.-EDA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2. EDA</a></span></li><li><span><a href=\"#3.-Subset-&amp;-Normalize\" data-toc-modified-id=\"3.-Subset-&amp;-Normalize-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>3. Subset &amp; Normalize</a></span></li><li><span><a href=\"#Calculate-correlation-matrix\" data-toc-modified-id=\"Calculate-correlation-matrix-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Calculate correlation matrix</a></span></li><li><span><a href=\"#4.-Calculate-the-eigenvalues-and-eigenvectors-from-the-correlation-matrix\" data-toc-modified-id=\"4.-Calculate-the-eigenvalues-and-eigenvectors-from-the-correlation-matrix-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>4. Calculate the eigenvalues and eigenvectors from the correlation matrix</a></span></li><li><span><a href=\"#5.-Calculate-and-plot-the-explained-variance\" data-toc-modified-id=\"5.-Calculate-and-plot-the-explained-variance-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>5. Calculate and plot the explained variance</a></span></li><li><span><a href=\"#$$-ExpVar_i-=-\\bigg(\\frac{eigenvalue_i}{\\sum_j^n{eigenvalue_j}}\\bigg)-*-100$$\" data-toc-modified-id=\"$$-ExpVar_i-=-\\bigg(\\frac{eigenvalue_i}{\\sum_j^n{eigenvalue_j}}\\bigg)-*-100$$-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span><div class=\"MathJax_Display MathJax_Processing\"></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-1\"> ExpVar_i = \\bigg(\\frac{eigenvalue_i}{\\sum_j^n{eigenvalue_j}}\\bigg) * 100</script></a></span></li><li><span><a href=\"#6.-Using-sklearn-For-PCA\" data-toc-modified-id=\"6.-Using-sklearn-For-PCA-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>6. Using sklearn For PCA</a></span></li><li><span><a href=\"#7.-Split-Data-to-80/20-and-Use-PCA-you-gon-in-6-as-X\" data-toc-modified-id=\"7.-Split-Data-to-80/20-and-Use-PCA-you-gon-in-6-as-X-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>7. Split Data to 80/20 and Use PCA you gon in 6 as X</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XebDJ3UnS3n3"
   },
   "source": [
    "![alt text](https://i.imgur.com/1WaY7aA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_-HjrL6S3n5"
   },
   "source": [
    "# Lab 6.4\n",
    "# *PCA Lab*\n",
    "\n",
    "**In this lab, we will:**\n",
    "- Explore how PCA is related to correlation.\n",
    "- Use PCA to perform dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 / area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T05:10:33.642287Z",
     "start_time": "2019-05-16T05:10:33.429626Z"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT LABRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T05:10:35.890574Z",
     "start_time": "2019-05-16T05:10:35.812753Z"
    }
   },
   "outputs": [],
   "source": [
    "breast_cancer_csv = '../../DATA/breast-cancer-wisconsin-data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EDA \n",
    "\n",
    "Explore dataset. Clean data. Find correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T01:10:16.792504Z",
     "start_time": "2019-05-16T01:10:16.786523Z"
    }
   },
   "source": [
    "### 3. Subset & Normalize\n",
    "\n",
    "Subset the data to only include all columns except diagnosis. We will be comparing the principal components to age specifically, so we are leaving age out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation matrix\n",
    "\n",
    "We will be using the correlation matrix to calculate the eigenvectors and eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the eigenvalues and eigenvectors from the correlation matrix\n",
    "\n",
    "numpy has a convenient function to calculate this:\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate and plot the explained variance\n",
    "\n",
    "A useful measure is the **explained variance**, which is calculated from the eigenvalues. \n",
    "\n",
    "The explained variance tells us how much information (variance) is captured by each principal component.\n",
    "\n",
    "### $$ ExpVar_i = \\bigg(\\frac{eigenvalue_i}{\\sum_j^n{eigenvalue_j}}\\bigg) * 100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cum_var_exp(eig_vals):\n",
    "    '''\n",
    "    Calculate Explained Variance from Eigenvalues\n",
    "    '''\n",
    "    return cum_var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var_exp(eig_vals):\n",
    "    \n",
    "    cum_var_exp = calculate_cum_var_exp(eig_vals)\n",
    "    \n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    component_number = [i+1 for i in range(len(cum_var_exp))]\n",
    "\n",
    "    plt.plot(component_number, cum_var_exp, lw=7)\n",
    "\n",
    "    plt.axhline(y=0, linewidth=5, color='grey', ls='dashed')\n",
    "    plt.axhline(y=100, linewidth=3, color='grey', ls='dashed')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([1,30])\n",
    "    ax.set_ylim([-5,105])\n",
    "\n",
    "    ax.set_ylabel('cumulative variance explained', fontsize=16)\n",
    "    ax.set_xlabel('component', fontsize=16)\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(12) \n",
    "\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(12) \n",
    "\n",
    "    ax.set_title('component vs cumulative variance explained\\n', fontsize=20)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Using sklearn For PCA\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "- Create an instance of PCA\n",
    "- Fit X\n",
    "- Plot the explained variance\n",
    "- Define n_components\n",
    "    - n_component\n",
    "- Apply dimensionality reduction to X\n",
    "    - transform\n",
    "- Create PairPlot of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Create an instance of PCA\n",
    "\n",
    "# Fit Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Plot explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Apply dimensionality reduction to Xs using transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Create PairPlot of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Split Data to 80/20 and Use PCA you gon in 6 as X\n",
    "\n",
    "Split data 80/20 and Use KNN to find score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/downloads/breast-cancer-wisconsin-data.zip/2)\n",
    "\n",
    "[Breast Cancer Machine Learning Prediction](https://gtraskas.github.io/post/breast_cancer/)\n",
    "\n",
    "[Understanding PCA (Principal Component Analysis) with Python](https://towardsdatascience.com/dive-into-pca-principal-component-analysis-with-python-43ded13ead21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "**Â© 2019 Data Science Institute of Australia**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab 5.3 - answers.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
